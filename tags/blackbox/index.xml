<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>blackbox on Sera Wang</title><link>https://selfsolo.com/tags/blackbox/</link><description>Recent content in blackbox on Sera Wang</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 15 Sep 2019 11:02:51 +0000</lastBuildDate><atom:link href="https://selfsolo.com/tags/blackbox/index.xml" rel="self" type="application/rss+xml"/><item><title>如何实现一个黑盒扫描器?</title><link>https://selfsolo.com/p/blackbox-scanner/</link><pubDate>Sun, 15 Sep 2019 11:02:51 +0000</pubDate><guid>https://selfsolo.com/p/blackbox-scanner/</guid><description>整体架构 黑盒扫描的目的主要有两个：
资产发现 漏洞扫描 扫描器的效率和表现方面，单机可以用多进程+协程的方式去提qps，资源够也可以使用分布式，如：kafka / celery（后者感觉更重一点，虽然能帮你做很多事情）
我踩坑设计了一个主要依靠redis做任务的分发和pull执行（主要想糙快猛地实现），现在看来效率的确是因为架构设计有问题导致整体表现不尽如人意。
自己后来想的一个理想的架构设计：
子域名搜集 子域名搜集是信息搜集里很关键的一步，因为它拓展了很大一部分的攻击面。下面是我对子域名搜集的实践。
我用python实现了一个子域名搜集工具，主要用到的方法有：
基于字典 开源情报 和 搜索引擎 IP反查 TLS证书获取 我使用的前者，部署最方便。
整体架构：
这是单机跑的非理想情况，4核8g，60%cpu，800-1500qps
几个大小问题：
域名泛解析 域名去重 比较依赖redis 泛解析有两种解决方式，一种是ip-domain的hash map超过了阈值，最后做清洗；另一种是查完了，就做一次 &amp;lt;随机前缀.目标域名&amp;gt;的查询，判断是否存在，这样（和清洗一个道理）。实际做下来是1方便，因为第二种方式，如果在做判断的同时，有其他做dns query的查到了结果，就会被绕过存入data。
域名去重是因为首先引入了开源情报和搜索引擎，还有后续得到的CNAME啊，NS啊之类的，不做去重，任务队列可能就大了两三倍。我去重主要依赖redis的set，这样又回引入大key问题，解决大key，可以根据域名的级数（多少个&amp;lt;.&amp;gt;）分去重set，也可以大key分小key，因为并发，暂时没想到好的设计，优化考虑用布隆过滤器去做去重。
依赖redis，前面有提到，后面就不赘述了。
敏感文件扫描 这个我实现的很简单，主要看了github上几个老前辈的实现，总结了一下，可以这样做：
对目标做一次全站链接爬取（需要考虑url去重） 根据links生成一级级目录 配合对应字典，做验证。 其实有了目录+对应漏洞的字典，主要就是验证了。这块同时可以验证的漏洞有很多，除了敏感文件泄漏，还有目录遍历，未授权访问等等。后者可以通过打分策略来做（实现比较low，也可以用图像识别，ML做）。
漏洞验证 可以找一个社区比较大的（poc贡献多），因为一个是自己写poc需要很多时间。</description></item></channel></rss>