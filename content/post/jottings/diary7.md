---
title: "校园杂记7：这是我等待爬虫爬完的第三个年头了.."
description: 读书时的碎碎念
date: 2017-10-22T21:14:23+08:00
tags:
    - 杂记
categories:
    - jottings
---



有人问我这几天在干嘛。

我想了一下，三点一线的日子啊…python，食堂，洗手间，要是有睡袋我可能就睡在电脑前面了吧…

码字之前，我比较想知道，python是不是光头最快的语言? 不是的话，那今天开始可以是了（雾）…



------

写代码的时候遇到解决不了的bug翻墙出去搜google 搜stackoverflow 搜github，换了七八个关键词，发现在犄角旮旯里的一个页面里 2006年有一个苦逼问了跟我一样的问题，然后十多年无人回复。

那时候感觉跨越时空两颗孤独的灵魂相通了……



------

礼拜一跟老师聊着聊着，

> 这个月你可以帮我写个（爬虫）工具吗，爬全国高校关于网络安全的通知。

毕竟是借给我服务器的老师... 该打工还是得打，task听上去很简单嘛，我就应了。那天是刚学了python写了个小crawler的第二天。

第二天把看了两天的core python programming剩下的部分着重看完了，开始看第二本python的书「deep in python crawler」

------

着重看了crawler部分之后，开始写task的代码了。

思考了一下，全国高校 网络安全 通知

全国高校，也就是要爬web上全部的.edu.cn后缀的网站，

关键词是网络安全和通知，一次正则检索。

为了省事，我百度了一下高校网址大全，把上面关于中国所有学校的链接爬了下来，放到edulinks.txt里，然后以此开始正式爬取关键词。

开始之前，总得写个demo吧，于是挑了几个学校的web找找信息，发现信息一点都不友好，每个学校的网站写的都是不一样的。

我就很奇怪，怎么还有学校的网站是gb2312编码的，爬出来一堆乱码，研究了一晚上request库如何decode和encode，才发现原来可以用requests库一句encoding搞定，utf-8大法好👌

…

…

…

于是一晚上就这么没了……

------

今天想的准确了一点，手头上有了基本的url，思路大概是这样：

1. 待爬取url存进一个urllist列表里，爬取网站下的所有url，写一个筛选函数，把不符合或者重复的url删除，（比如说只能是这个域名下的）
2. 筛选过的url添加进一个待爬列表，一轮爬取一个
3. 筛选出关于关键字的信息，添加进一个信息列表，（这个列表是个二维数组，对应是学校名称）

然后实现过程中，

报错？ 忽略，try except continue三连

拒绝访问10054？ 加个time模块，爬一次睡一秒

invalid error？ 加个UserAgent头再爬

又是编码？ #coding=utf-8,encoding=’utf-8’

…

…

找不到url?

我：？？？？？？？？？？？？

………

平复了两个小时的心情，分析了一下，一个域名，它下面的有些网站，不会直接在url上显示，学校还好，一般不会加个js动态添加url，但还是有点麻烦，需要手动搜索search关键字，才会跳出那些搜索到的页面，我的爬虫，真的。。。做不到QAQ

好吧，想了一下，需要再加几个函数……

思路大概先这样：

对于一个学校的网站，先正则找到搜索框，然后填数据post过去，也就获取了出现的url了，其中还有很多很多细节要注意..休息一下再想吧…

…最后说句仿佛很有哲理的话..写代码就像人生，踩得坑多了，人也就歇菜了。
